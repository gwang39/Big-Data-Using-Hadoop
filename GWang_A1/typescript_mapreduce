Script started on Sun 16 Sep 2018 10:40:25 AM EDT
]777;notify;Command completed;jps]0;gwang39@hdserver:~/hadoop-2.7.3]7;file://hdserver/home/gwang39/hadoop-2.7.3[?1034h[gwang39@hdserver hadoop-2.7.3]$ jpscat typescript[3@scrip[C[C[C[C[C[C[C[C[C[C[C[C-a[Kvi typescriptcd[Kexit[2Pwqqwexitbin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar grep input output 'dfs[a-z.]+'[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cexit[Ksbin/stop-yarn.sh[1Pdfs.shall.shjps[Kbin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar grep input output 'dfs[a-z.]+'[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cdfs dfs -mkdir /user/gwang39[K[K/gwang39adoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar grep input output 'dfs[a-z.]+'
18/09/16 10:40:31 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
18/09/16 10:40:31 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
18/09/16 10:40:31 INFO input.FileInputFormat: Total input paths to process : 29
18/09/16 10:40:31 INFO mapreduce.JobSubmitter: number of splits:29
18/09/16 10:40:31 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1988281306_0001
18/09/16 10:40:32 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
18/09/16 10:40:32 INFO mapreduce.Job: Running job: job_local1988281306_0001
18/09/16 10:40:32 INFO mapred.LocalJobRunner: OutputCommitter set in config null
18/09/16 10:40:32 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/09/16 10:40:32 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
18/09/16 10:40:32 INFO mapred.LocalJobRunner: Waiting for map tasks
18/09/16 10:40:32 INFO mapred.LocalJobRunner: Starting task: attempt_local1988281306_0001_m_000000_0
18/09/16 10:40:32 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/09/16 10:40:32 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
18/09/16 10:40:32 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/gwang39/input/log4j.properties:0+11237
18/09/16 10:40:32 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
18/09/16 10:40:32 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
18/09/16 10:40:32 INFO mapred.MapTask: soft limit at 83886080
18/09/16 10:40:32 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
18/09/16 10:40:32 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
18/09/16 10:40:33 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
18/09/16 10:40:33 INFO mapreduce.Job: Job job_local1988281306_0001 running in uber mode : false
18/09/16 10:40:33 INFO mapreduce.Job:  map 0% reduce 0%
18/09/16 10:40:33 INFO mapred.LocalJobRunner: 
18/09/16 10:40:33 INFO mapred.MapTask: Starting flush of map output
18/09/16 10:40:33 INFO mapred.MapTask: Spilling map output
18/09/16 10:40:33 INFO mapred.MapTask: bufstart = 0; bufend = 279; bufvoid = 104857600
18/09/16 10:40:33 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214364(104857456); length = 33/6553600
18/09/16 10:40:33 INFO mapred.MapTask: Finished spill 0
18/09/16 10:40:33 INFO mapred.Task: Task:attempt_local1988281306_0001_m_000000_0 is done. And is in the process of committing
18/09/16 10:40:33 INFO mapred.LocalJobRunner: map
18/09/16 10:40:33 INFO mapred.Task: Task 'attempt_local1988281306_0001_m_000000_0' done.
18/09/16 10:40:33 INFO mapred.LocalJobRunner: Finishing task: attempt_local1988281306_0001_m_000000_0
18/09/16 10:40:33 INFO mapred.LocalJobRunner: Starting task: attempt_local1988281306_0001_m_000001_0
18/09/16 10:40:33 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/09/16 10:40:33 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
18/09/16 10:40:33 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/gwang39/input/hadoop-policy.xml:0+9683
18/09/16 10:40:33 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
18/09/16 10:40:33 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
18/09/16 10:40:33 INFO mapred.MapTask: soft limit at 83886080
18/09/16 10:40:33 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
18/09/16 10:40:33 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
18/09/16 10:40:33 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
18/09/16 10:40:33 INFO mapred.LocalJobRunner: 
18/09/16 10:40:33 INFO mapred.MapTask: Starting flush of map output
18/09/16 10:40:33 INFO mapred.MapTask: Spilling map output
18/09/16 10:40:33 INFO mapred.MapTask: bufstart = 0; bufend = 17; bufvoid = 104857600
18/09/16 10:40:33 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
18/09/16 10:40:33 INFO mapred.MapTask: Finished spill 0
18/09/16 10:40:33 INFO mapred.Task: Task:attempt_local1988281306_0001_m_000001_0 is done. And is in the process of committing
18/09/16 10:40:33 INFO mapred.LocalJobRunner: map
18/09/16 10:40:33 INFO mapred.Task: Task 'attempt_local1988281306_0001_m_000001_0' done.
18/09/16 10:40:33 INFO mapred.LocalJobRunner: Finishing task: attempt_local1988281306_0001_m_000001_0
18/09/16 10:40:33 INFO mapred.LocalJobRunner: Starting task: attempt_local1988281306_0001_m_000002_0
18/09/16 10:40:33 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/09/16 10:40:33 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
18/09/16 10:40:33 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/gwang39/input/kms-site.xml:0+5511
18/09/16 10:40:34 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
18/09/16 10:40:34 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
18/09/16 10:40:34 INFO mapred.MapTask: soft limit at 83886080
18/09/16 10:40:34 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
18/09/16 10:40:34 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
18/09/16 10:40:34 INFO mapreduce.Job:  map 100% reduce 0%
18/09/16 10:40:34 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
18/09/16 10:40:34 INFO mapred.LocalJobRunner: 
18/09/16 10:40:34 INFO mapred.MapTask: Starting flush of map output
18/09/16 10:40:34 INFO mapred.Task: Task:attempt_local1988281306_0001_m_000002_0 is done. And is in the process of committing
18/09/16 10:40:34 INFO mapred.LocalJobRunner: map
18/09/16 10:40:34 INFO mapred.Task: Task 'attempt_local1988281306_0001_m_000002_0' done.
18/09/16 10:40:34 INFO mapred.LocalJobRunner: Finishing task: attempt_local1988281306_0001_m_000002_0
18/09/16 10:40:34 INFO mapred.LocalJobRunner: Starting task: attempt_local1988281306_0001_m_000003_0
18/09/16 10:40:34 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/09/16 10:40:34 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
18/09/16 10:40:34 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/gwang39/input/yarn-env.sh:0+4567
18/09/16 10:40:34 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
18/09/16 10:40:34 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
18/09/16 10:40:34 INFO mapred.MapTask: soft limit at 83886080
18/09/16 10:40:34 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
18/09/16 10:40:34 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
18/09/16 10:40:34 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
18/09/16 10:40:34 INFO mapred.LocalJobRunner: 
18/09/16 10:40:34 INFO mapred.MapTask: Starting flush of map output
18/09/16 10:40:34 INFO mapred.Task: Task:attempt_local1988281306_0001_m_000003_0 is done. And is in the process of committing
18/09/16 10:40:34 INFO mapred.LocalJobRunner: map
18/09/16 10:40:34 INFO mapred.Task: Task 'attempt_local1988281306_0001_m_000003_0' done.
18/09/16 10:40:34 INFO mapred.LocalJobRunner: Finishing task: attempt_local1988281306_0001_m_000003_0
18/09/16 10:40:34 INFO mapred.LocalJobRunner: Starting task: attempt_local1988281306_0001_m_000004_0
18/09/16 10:40:34 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/09/16 10:40:34 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
18/09/16 10:40:34 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/gwang39/input/capacity-scheduler.xml:0+4436
18/09/16 10:40:34 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
18/09/16 10:40:34 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
18/09/16 10:40:34 INFO mapred.MapTask: soft limit at 83886080
18/09/16 10:40:34 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
18/09/16 10:40:34 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
18/09/16 10:40:34 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
18/09/16 10:40:34 INFO mapred.LocalJobRunner: 
18/09/16 10:40:34 INFO mapred.MapTask: Starting flush of map output
18/09/16 10:40:34 INFO mapred.Task: Task:attempt_local1988281306_0001_m_000004_0 is done. And is in the process of committing
18/09/16 10:40:34 INFO mapred.LocalJobRunner: map
18/09/16 10:40:34 INFO mapred.Task: Task 'attempt_local1988281306_0001_m_000004_0' done.
18/09/16 10:40:34 INFO mapred.LocalJobRunner: Finishing task: attempt_local1988281306_0001_m_000004_0
18/09/16 10:40:34 INFO mapred.LocalJobRunner: Starting task: attempt_local1988281306_0001_m_000005_0
18/09/16 10:40:34 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/09/16 10:40:34 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
18/09/16 10:40:34 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/gwang39/input/hadoop-env.sh:0+4272
18/09/16 10:40:34 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
18/09/16 10:40:34 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
18/09/16 10:40:34 INFO mapred.MapTask: soft limit at 83886080
18/09/16 10:40:34 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
18/09/16 10:40:34 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
18/09/16 10:40:34 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
18/09/16 10:40:34 INFO mapred.LocalJobRunner: 
18/09/16 10:40:34 INFO mapred.MapTask: Starting flush of map output
18/09/16 10:40:34 INFO mapred.MapTask: Spilling map output
18/09/16 10:40:34 INFO mapred.MapTask: bufstart = 0; bufend = 50; bufvoid = 104857600
18/09/16 10:40:34 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
18/09/16 10:40:34 INFO mapred.MapTask: Finished spill 0
18/09/16 10:40:34 INFO mapred.Task: Task:attempt_local1988281306_0001_m_000005_0 is done. And is in the process of committing
18/09/16 10:40:34 INFO mapred.LocalJobRunner: map
18/09/16 10:40:34 INFO mapred.Task: Task 'attempt_local1988281306_0001_m_000005_0' done.
18/09/16 10:40:34 INFO mapred.LocalJobRunner: Finishing task: attempt_local1988281306_0001_m_000005_0
18/09/16 10:40:34 INFO mapred.LocalJobRunner: Starting task: attempt_local1988281306_0001_m_000006_0
18/09/16 10:40:34 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/09/16 10:40:34 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
18/09/16 10:40:34 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/gwang39/input/mapred-queues.xml.template:0+4113
18/09/16 10:40:34 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
18/09/16 10:40:34 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
18/09/16 10:40:34 INFO mapred.MapTask: soft limit at 83886080
18/09/16 10:40:34 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
18/09/16 10:40:34 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
18/09/16 10:40:34 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
18/09/16 10:40:34 INFO mapred.LocalJobRunner: 
18/09/16 10:40:34 INFO mapred.MapTask: Starting flush of map output
18/09/16 10:40:34 INFO mapred.Task: Task:attempt_local1988281306_0001_m_000006_0 is done. And is in the process of committing
18/09/16 10:40:34 INFO mapred.LocalJobRunner: map
18/09/16 10:40:34 INFO mapred.Task: Task 'attempt_local1988281306_0001_m_000006_0' done.
18/09/16 10:40:34 INFO mapred.LocalJobRunner: Finishing task: attempt_local1988281306_0001_m_000006_0
18/09/16 10:40:34 INFO mapred.LocalJobRunner: Starting task: attempt_local1988281306_0001_m_000007_0
18/09/16 10:40:34 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/09/16 10:40:34 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
18/09/16 10:40:35 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/gwang39/input/hadoop-env.cmd:0+3589
18/09/16 10:40:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
18/09/16 10:40:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
18/09/16 10:40:35 INFO mapred.MapTask: soft limit at 83886080
18/09/16 10:40:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
18/09/16 10:40:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
18/09/16 10:40:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
18/09/16 10:40:35 INFO mapred.LocalJobRunner: 
18/09/16 10:40:35 INFO mapred.MapTask: Starting flush of map output
18/09/16 10:40:35 INFO mapred.MapTask: Spilling map output
18/09/16 10:40:35 INFO mapred.MapTask: bufstart = 0; bufend = 50; bufvoid = 104857600
18/09/16 10:40:35 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
18/09/16 10:40:35 INFO mapred.MapTask: Finished spill 0
18/09/16 10:40:35 INFO mapred.Task: Task:attempt_local1988281306_0001_m_000007_0 is done. And is in the process of committing
18/09/16 10:40:35 INFO mapred.LocalJobRunner: map
18/09/16 10:40:35 INFO mapred.Task: Task 'attempt_local1988281306_0001_m_000007_0' done.
18/09/16 10:40:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1988281306_0001_m_000007_0
18/09/16 10:40:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1988281306_0001_m_000008_0
18/09/16 10:40:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/09/16 10:40:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
18/09/16 10:40:35 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/gwang39/input/kms-acls.xml:0+3518
18/09/16 10:40:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
18/09/16 10:40:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
18/09/16 10:40:35 INFO mapred.MapTask: soft limit at 83886080
18/09/16 10:40:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
18/09/16 10:40:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
18/09/16 10:40:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
18/09/16 10:40:35 INFO mapred.LocalJobRunner: 
18/09/16 10:40:35 INFO mapred.MapTask: Starting flush of map output
18/09/16 10:40:35 INFO mapred.Task: Task:attempt_local1988281306_0001_m_000008_0 is done. And is in the process of committing
18/09/16 10:40:35 INFO mapred.LocalJobRunner: map
18/09/16 10:40:35 INFO mapred.Task: Task 'attempt_local1988281306_0001_m_000008_0' done.
18/09/16 10:40:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1988281306_0001_m_000008_0
18/09/16 10:40:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1988281306_0001_m_000009_0
18/09/16 10:40:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/09/16 10:40:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
18/09/16 10:40:35 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/gwang39/input/hadoop-metrics2.properties:0+2598
18/09/16 10:40:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
18/09/16 10:40:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
18/09/16 10:40:35 INFO mapred.MapTask: soft limit at 83886080
18/09/16 10:40:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
18/09/16 10:40:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
18/09/16 10:40:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
18/09/16 10:40:35 INFO mapred.LocalJobRunner: 
18/09/16 10:40:35 INFO mapred.MapTask: Starting flush of map output
18/09/16 10:40:35 INFO mapred.Task: Task:attempt_local1988281306_0001_m_000009_0 is done. And is in the process of committing
18/09/16 10:40:35 INFO mapred.LocalJobRunner: map
18/09/16 10:40:35 INFO mapred.Task: Task 'attempt_local1988281306_0001_m_000009_0' done.
18/09/16 10:40:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1988281306_0001_m_000009_0
18/09/16 10:40:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1988281306_0001_m_000010_0
18/09/16 10:40:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/09/16 10:40:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
18/09/16 10:40:35 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/gwang39/input/hadoop-metrics.properties:0+2490
18/09/16 10:40:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
18/09/16 10:40:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
18/09/16 10:40:35 INFO mapred.MapTask: soft limit at 83886080
18/09/16 10:40:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
18/09/16 10:40:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
18/09/16 10:40:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
18/09/16 10:40:35 INFO mapred.LocalJobRunner: 
18/09/16 10:40:35 INFO mapred.MapTask: Starting flush of map output
18/09/16 10:40:35 INFO mapred.MapTask: Spilling map output
18/09/16 10:40:35 INFO mapred.MapTask: bufstart = 0; bufend = 170; bufvoid = 104857600
18/09/16 10:40:35 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214364(104857456); length = 33/6553600
18/09/16 10:40:35 INFO mapred.MapTask: Finished spill 0
18/09/16 10:40:35 INFO mapreduce.Job:  map 34% reduce 0%
18/09/16 10:40:35 INFO mapred.Task: Task:attempt_local1988281306_0001_m_000010_0 is done. And is in the process of committing
18/09/16 10:40:35 INFO mapred.LocalJobRunner: map
18/09/16 10:40:35 INFO mapred.Task: Task 'attempt_local1988281306_0001_m_000010_0' done.
18/09/16 10:40:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1988281306_0001_m_000010_0
18/09/16 10:40:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1988281306_0001_m_000011_0
18/09/16 10:40:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/09/16 10:40:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
18/09/16 10:40:35 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/gwang39/input/ssl-client.xml.example:0+2316
18/09/16 10:40:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
18/09/16 10:40:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
18/09/16 10:40:35 INFO mapred.MapTask: soft limit at 83886080
18/09/16 10:40:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
18/09/16 10:40:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
18/09/16 10:40:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
18/09/16 10:40:35 INFO mapred.LocalJobRunner: 
18/09/16 10:40:35 INFO mapred.MapTask: Starting flush of map output
18/09/16 10:40:35 INFO mapred.Task: Task:attempt_local1988281306_0001_m_000011_0 is done. And is in the process of committing
18/09/16 10:40:35 INFO mapred.LocalJobRunner: map
18/09/16 10:40:35 INFO mapred.Task: Task 'attempt_local1988281306_0001_m_000011_0' done.
18/09/16 10:40:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1988281306_0001_m_000011_0
18/09/16 10:40:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1988281306_0001_m_000012_0
18/09/16 10:40:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/09/16 10:40:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
18/09/16 10:40:35 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/gwang39/input/ssl-server.xml.example:0+2268
18/09/16 10:40:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
18/09/16 10:40:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
18/09/16 10:40:35 INFO mapred.MapTask: soft limit at 83886080
18/09/16 10:40:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
18/09/16 10:40:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
18/09/16 10:40:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
18/09/16 10:40:35 INFO mapred.LocalJobRunner: 
18/09/16 10:40:35 INFO mapred.MapTask: Starting flush of map output
18/09/16 10:40:35 INFO mapred.Task: Task:attempt_local1988281306_0001_m_000012_0 is done. And is in the process of committing
18/09/16 10:40:35 INFO mapred.LocalJobRunner: map
18/09/16 10:40:35 INFO mapred.Task: Task 'attempt_local1988281306_0001_m_000012_0' done.
18/09/16 10:40:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1988281306_0001_m_000012_0
18/09/16 10:40:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1988281306_0001_m_000013_0
18/09/16 10:40:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/09/16 10:40:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
18/09/16 10:40:35 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/gwang39/input/yarn-env.cmd:0+2191
18/09/16 10:40:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
18/09/16 10:40:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
18/09/16 10:40:35 INFO mapred.MapTask: soft limit at 83886080
18/09/16 10:40:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
18/09/16 10:40:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
18/09/16 10:40:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
18/09/16 10:40:35 INFO mapred.LocalJobRunner: 
18/09/16 10:40:35 INFO mapred.MapTask: Starting flush of map output
18/09/16 10:40:35 INFO mapred.Task: Task:attempt_local1988281306_0001_m_000013_0 is done. And is in the process of committing
18/09/16 10:40:35 INFO mapred.LocalJobRunner: map
18/09/16 10:40:35 INFO mapred.Task: Task 'attempt_local1988281306_0001_m_000013_0' done.
18/09/16 10:40:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1988281306_0001_m_000013_0
18/09/16 10:40:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1988281306_0001_m_000014_0
18/09/16 10:40:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/09/16 10:40:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
18/09/16 10:40:35 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/gwang39/input/httpfs-log4j.properties:0+1657
18/09/16 10:40:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
18/09/16 10:40:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
18/09/16 10:40:35 INFO mapred.MapTask: soft limit at 83886080
18/09/16 10:40:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
18/09/16 10:40:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
18/09/16 10:40:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
18/09/16 10:40:35 INFO mapred.LocalJobRunner: 
18/09/16 10:40:35 INFO mapred.MapTask: Starting flush of map output
18/09/16 10:40:35 INFO mapred.Task: Task:attempt_local1988281306_0001_m_000014_0 is done. And is in the process of committing
18/09/16 10:40:35 INFO mapred.LocalJobRunner: map
18/09/16 10:40:35 INFO mapred.Task: Task 'attempt_local1988281306_0001_m_000014_0' done.
18/09/16 10:40:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1988281306_0001_m_000014_0
18/09/16 10:40:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1988281306_0001_m_000015_0
18/09/16 10:40:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/09/16 10:40:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
18/09/16 10:40:35 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/gwang39/input/kms-log4j.properties:0+1631
18/09/16 10:40:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
18/09/16 10:40:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
18/09/16 10:40:35 INFO mapred.MapTask: soft limit at 83886080
18/09/16 10:40:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
18/09/16 10:40:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
18/09/16 10:40:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
18/09/16 10:40:35 INFO mapred.LocalJobRunner: 
18/09/16 10:40:35 INFO mapred.MapTask: Starting flush of map output
18/09/16 10:40:35 INFO mapred.Task: Task:attempt_local1988281306_0001_m_000015_0 is done. And is in the process of committing
18/09/16 10:40:35 INFO mapred.LocalJobRunner: map
18/09/16 10:40:35 INFO mapred.Task: Task 'attempt_local1988281306_0001_m_000015_0' done.
18/09/16 10:40:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1988281306_0001_m_000015_0
18/09/16 10:40:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1988281306_0001_m_000016_0
18/09/16 10:40:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/09/16 10:40:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
18/09/16 10:40:35 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/gwang39/input/kms-env.sh:0+1527
18/09/16 10:40:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
18/09/16 10:40:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
18/09/16 10:40:35 INFO mapred.MapTask: soft limit at 83886080
18/09/16 10:40:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
18/09/16 10:40:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
18/09/16 10:40:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
18/09/16 10:40:35 INFO mapred.LocalJobRunner: 
18/09/16 10:40:35 INFO mapred.MapTask: Starting flush of map output
18/09/16 10:40:35 INFO mapred.Task: Task:attempt_local1988281306_0001_m_000016_0 is done. And is in the process of committing
18/09/16 10:40:35 INFO mapred.LocalJobRunner: map
18/09/16 10:40:35 INFO mapred.Task: Task 'attempt_local1988281306_0001_m_000016_0' done.
18/09/16 10:40:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1988281306_0001_m_000016_0
18/09/16 10:40:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1988281306_0001_m_000017_0
18/09/16 10:40:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/09/16 10:40:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
18/09/16 10:40:35 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/gwang39/input/httpfs-env.sh:0+1449
18/09/16 10:40:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
18/09/16 10:40:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
18/09/16 10:40:35 INFO mapred.MapTask: soft limit at 83886080
18/09/16 10:40:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
18/09/16 10:40:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
18/09/16 10:40:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
18/09/16 10:40:35 INFO mapred.LocalJobRunner: 
18/09/16 10:40:35 INFO mapred.MapTask: Starting flush of map output
18/09/16 10:40:35 INFO mapred.Task: Task:attempt_local1988281306_0001_m_000017_0 is done. And is in the process of committing
18/09/16 10:40:35 INFO mapred.LocalJobRunner: map
18/09/16 10:40:35 INFO mapred.Task: Task 'attempt_local1988281306_0001_m_000017_0' done.
18/09/16 10:40:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1988281306_0001_m_000017_0
18/09/16 10:40:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1988281306_0001_m_000018_0
18/09/16 10:40:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/09/16 10:40:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
18/09/16 10:40:35 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/gwang39/input/mapred-env.sh:0+1383
18/09/16 10:40:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
18/09/16 10:40:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
18/09/16 10:40:35 INFO mapred.MapTask: soft limit at 83886080
18/09/16 10:40:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
18/09/16 10:40:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
18/09/16 10:40:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
18/09/16 10:40:35 INFO mapred.LocalJobRunner: 
18/09/16 10:40:35 INFO mapred.MapTask: Starting flush of map output
18/09/16 10:40:35 INFO mapred.Task: Task:attempt_local1988281306_0001_m_000018_0 is done. And is in the process of committing
18/09/16 10:40:35 INFO mapred.LocalJobRunner: map
18/09/16 10:40:35 INFO mapred.Task: Task 'attempt_local1988281306_0001_m_000018_0' done.
18/09/16 10:40:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1988281306_0001_m_000018_0
18/09/16 10:40:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1988281306_0001_m_000019_0
18/09/16 10:40:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/09/16 10:40:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
18/09/16 10:40:35 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/gwang39/input/configuration.xsl:0+1335
18/09/16 10:40:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
18/09/16 10:40:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
18/09/16 10:40:35 INFO mapred.MapTask: soft limit at 83886080
18/09/16 10:40:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
18/09/16 10:40:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
18/09/16 10:40:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
18/09/16 10:40:35 INFO mapred.LocalJobRunner: 
18/09/16 10:40:35 INFO mapred.MapTask: Starting flush of map output
18/09/16 10:40:35 INFO mapred.Task: Task:attempt_local1988281306_0001_m_000019_0 is done. And is in the process of committing
18/09/16 10:40:35 INFO mapred.LocalJobRunner: map
18/09/16 10:40:35 INFO mapred.Task: Task 'attempt_local1988281306_0001_m_000019_0' done.
18/09/16 10:40:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1988281306_0001_m_000019_0
18/09/16 10:40:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1988281306_0001_m_000020_0
18/09/16 10:40:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/09/16 10:40:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
18/09/16 10:40:35 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/gwang39/input/mapred-env.cmd:0+931
18/09/16 10:40:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
18/09/16 10:40:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
18/09/16 10:40:35 INFO mapred.MapTask: soft limit at 83886080
18/09/16 10:40:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
18/09/16 10:40:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
18/09/16 10:40:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
18/09/16 10:40:35 INFO mapred.LocalJobRunner: 
18/09/16 10:40:35 INFO mapred.MapTask: Starting flush of map output
18/09/16 10:40:35 INFO mapred.Task: Task:attempt_local1988281306_0001_m_000020_0 is done. And is in the process of committing
18/09/16 10:40:35 INFO mapred.LocalJobRunner: map
18/09/16 10:40:35 INFO mapred.Task: Task 'attempt_local1988281306_0001_m_000020_0' done.
18/09/16 10:40:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1988281306_0001_m_000020_0
18/09/16 10:40:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1988281306_0001_m_000021_0
18/09/16 10:40:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/09/16 10:40:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
18/09/16 10:40:35 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/gwang39/input/core-site.xml:0+884
18/09/16 10:40:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
18/09/16 10:40:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
18/09/16 10:40:35 INFO mapred.MapTask: soft limit at 83886080
18/09/16 10:40:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
18/09/16 10:40:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
18/09/16 10:40:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
18/09/16 10:40:35 INFO mapred.LocalJobRunner: 
18/09/16 10:40:35 INFO mapred.MapTask: Starting flush of map output
18/09/16 10:40:35 INFO mapred.Task: Task:attempt_local1988281306_0001_m_000021_0 is done. And is in the process of committing
18/09/16 10:40:35 INFO mapred.LocalJobRunner: map
18/09/16 10:40:35 INFO mapred.Task: Task 'attempt_local1988281306_0001_m_000021_0' done.
18/09/16 10:40:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1988281306_0001_m_000021_0
18/09/16 10:40:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1988281306_0001_m_000022_0
18/09/16 10:40:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/09/16 10:40:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
18/09/16 10:40:35 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/gwang39/input/hdfs-site.xml:0+867
18/09/16 10:40:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
18/09/16 10:40:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
18/09/16 10:40:35 INFO mapred.MapTask: soft limit at 83886080
18/09/16 10:40:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
18/09/16 10:40:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
18/09/16 10:40:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
18/09/16 10:40:35 INFO mapred.LocalJobRunner: 
18/09/16 10:40:35 INFO mapred.MapTask: Starting flush of map output
18/09/16 10:40:35 INFO mapred.MapTask: Spilling map output
18/09/16 10:40:35 INFO mapred.MapTask: bufstart = 0; bufend = 24; bufvoid = 104857600
18/09/16 10:40:35 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
18/09/16 10:40:35 INFO mapred.MapTask: Finished spill 0
18/09/16 10:40:35 INFO mapred.Task: Task:attempt_local1988281306_0001_m_000022_0 is done. And is in the process of committing
18/09/16 10:40:35 INFO mapred.LocalJobRunner: map
18/09/16 10:40:35 INFO mapred.Task: Task 'attempt_local1988281306_0001_m_000022_0' done.
18/09/16 10:40:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1988281306_0001_m_000022_0
18/09/16 10:40:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1988281306_0001_m_000023_0
18/09/16 10:40:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/09/16 10:40:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
18/09/16 10:40:35 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/gwang39/input/mapred-site.xml.template:0+758
18/09/16 10:40:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
18/09/16 10:40:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
18/09/16 10:40:35 INFO mapred.MapTask: soft limit at 83886080
18/09/16 10:40:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
18/09/16 10:40:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
18/09/16 10:40:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
18/09/16 10:40:35 INFO mapred.LocalJobRunner: 
18/09/16 10:40:35 INFO mapred.MapTask: Starting flush of map output
18/09/16 10:40:35 INFO mapred.Task: Task:attempt_local1988281306_0001_m_000023_0 is done. And is in the process of committing
18/09/16 10:40:35 INFO mapred.LocalJobRunner: map
18/09/16 10:40:35 INFO mapred.Task: Task 'attempt_local1988281306_0001_m_000023_0' done.
18/09/16 10:40:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1988281306_0001_m_000023_0
18/09/16 10:40:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1988281306_0001_m_000024_0
18/09/16 10:40:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/09/16 10:40:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
18/09/16 10:40:35 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/gwang39/input/yarn-site.xml:0+690
18/09/16 10:40:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
18/09/16 10:40:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
18/09/16 10:40:35 INFO mapred.MapTask: soft limit at 83886080
18/09/16 10:40:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
18/09/16 10:40:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
18/09/16 10:40:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
18/09/16 10:40:35 INFO mapred.LocalJobRunner: 
18/09/16 10:40:35 INFO mapred.MapTask: Starting flush of map output
18/09/16 10:40:35 INFO mapred.Task: Task:attempt_local1988281306_0001_m_000024_0 is done. And is in the process of committing
18/09/16 10:40:35 INFO mapred.LocalJobRunner: map
18/09/16 10:40:35 INFO mapred.Task: Task 'attempt_local1988281306_0001_m_000024_0' done.
18/09/16 10:40:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1988281306_0001_m_000024_0
18/09/16 10:40:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1988281306_0001_m_000025_0
18/09/16 10:40:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/09/16 10:40:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
18/09/16 10:40:35 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/gwang39/input/httpfs-site.xml:0+620
18/09/16 10:40:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
18/09/16 10:40:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
18/09/16 10:40:35 INFO mapred.MapTask: soft limit at 83886080
18/09/16 10:40:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
18/09/16 10:40:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
18/09/16 10:40:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
18/09/16 10:40:35 INFO mapred.LocalJobRunner: 
18/09/16 10:40:35 INFO mapred.MapTask: Starting flush of map output
18/09/16 10:40:35 INFO mapred.Task: Task:attempt_local1988281306_0001_m_000025_0 is done. And is in the process of committing
18/09/16 10:40:35 INFO mapred.LocalJobRunner: map
18/09/16 10:40:35 INFO mapred.Task: Task 'attempt_local1988281306_0001_m_000025_0' done.
18/09/16 10:40:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1988281306_0001_m_000025_0
18/09/16 10:40:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1988281306_0001_m_000026_0
18/09/16 10:40:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/09/16 10:40:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
18/09/16 10:40:35 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/gwang39/input/container-executor.cfg:0+318
18/09/16 10:40:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
18/09/16 10:40:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
18/09/16 10:40:35 INFO mapred.MapTask: soft limit at 83886080
18/09/16 10:40:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
18/09/16 10:40:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
18/09/16 10:40:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
18/09/16 10:40:35 INFO mapred.LocalJobRunner: 
18/09/16 10:40:35 INFO mapred.MapTask: Starting flush of map output
18/09/16 10:40:35 INFO mapred.Task: Task:attempt_local1988281306_0001_m_000026_0 is done. And is in the process of committing
18/09/16 10:40:35 INFO mapred.LocalJobRunner: map
18/09/16 10:40:35 INFO mapred.Task: Task 'attempt_local1988281306_0001_m_000026_0' done.
18/09/16 10:40:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1988281306_0001_m_000026_0
18/09/16 10:40:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1988281306_0001_m_000027_0
18/09/16 10:40:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/09/16 10:40:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
18/09/16 10:40:35 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/gwang39/input/httpfs-signature.secret:0+21
18/09/16 10:40:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
18/09/16 10:40:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
18/09/16 10:40:35 INFO mapred.MapTask: soft limit at 83886080
18/09/16 10:40:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
18/09/16 10:40:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
18/09/16 10:40:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
18/09/16 10:40:35 INFO mapred.LocalJobRunner: 
18/09/16 10:40:35 INFO mapred.MapTask: Starting flush of map output
18/09/16 10:40:35 INFO mapred.Task: Task:attempt_local1988281306_0001_m_000027_0 is done. And is in the process of committing
18/09/16 10:40:35 INFO mapred.LocalJobRunner: map
18/09/16 10:40:35 INFO mapred.Task: Task 'attempt_local1988281306_0001_m_000027_0' done.
18/09/16 10:40:35 INFO mapred.LocalJobRunner: Finishing task: attempt_local1988281306_0001_m_000027_0
18/09/16 10:40:35 INFO mapred.LocalJobRunner: Starting task: attempt_local1988281306_0001_m_000028_0
18/09/16 10:40:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/09/16 10:40:35 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
18/09/16 10:40:35 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/gwang39/input/slaves:0+10
18/09/16 10:40:35 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
18/09/16 10:40:35 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
18/09/16 10:40:35 INFO mapred.MapTask: soft limit at 83886080
18/09/16 10:40:35 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
18/09/16 10:40:35 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
18/09/16 10:40:35 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
18/09/16 10:40:36 INFO mapred.LocalJobRunner: 
18/09/16 10:40:36 INFO mapred.MapTask: Starting flush of map output
18/09/16 10:40:36 INFO mapred.Task: Task:attempt_local1988281306_0001_m_000028_0 is done. And is in the process of committing
18/09/16 10:40:36 INFO mapred.LocalJobRunner: map
18/09/16 10:40:36 INFO mapred.Task: Task 'attempt_local1988281306_0001_m_000028_0' done.
18/09/16 10:40:36 INFO mapred.LocalJobRunner: Finishing task: attempt_local1988281306_0001_m_000028_0
18/09/16 10:40:36 INFO mapred.LocalJobRunner: map task executor complete.
18/09/16 10:40:36 INFO mapred.LocalJobRunner: Waiting for reduce tasks
18/09/16 10:40:36 INFO mapred.LocalJobRunner: Starting task: attempt_local1988281306_0001_r_000000_0
18/09/16 10:40:36 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/09/16 10:40:36 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
18/09/16 10:40:36 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7a3c5c
18/09/16 10:40:36 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=372873632, maxSingleShuffleLimit=93218408, mergeThreshold=246096608, ioSortFactor=10, memToMemMergeOutputsThreshold=10
18/09/16 10:40:36 INFO reduce.EventFetcher: attempt_local1988281306_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
18/09/16 10:40:36 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1988281306_0001_m_000009_0 decomp: 2 len: 6 to MEMORY
18/09/16 10:40:36 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1988281306_0001_m_000009_0
18/09/16 10:40:36 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
18/09/16 10:40:36 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1988281306_0001_m_000022_0 decomp: 28 len: 32 to MEMORY
18/09/16 10:40:36 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:206)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
18/09/16 10:40:36 INFO reduce.InMemoryMapOutput: Read 28 bytes from map-output for attempt_local1988281306_0001_m_000022_0
18/09/16 10:40:36 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 28, inMemoryMapOutputs.size() -> 2, commitMemory -> 2, usedMemory ->30
18/09/16 10:40:36 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1988281306_0001_m_000023_0 decomp: 2 len: 6 to MEMORY
18/09/16 10:40:36 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1988281306_0001_m_000023_0
18/09/16 10:40:36 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 3, commitMemory -> 30, usedMemory ->32
18/09/16 10:40:36 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1988281306_0001_m_000010_0 decomp: 109 len: 113 to MEMORY
18/09/16 10:40:36 INFO reduce.InMemoryMapOutput: Read 109 bytes from map-output for attempt_local1988281306_0001_m_000010_0
18/09/16 10:40:36 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 109, inMemoryMapOutputs.size() -> 4, commitMemory -> 32, usedMemory ->141
18/09/16 10:40:36 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1988281306_0001_m_000008_0 decomp: 2 len: 6 to MEMORY
18/09/16 10:40:36 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1988281306_0001_m_000008_0
18/09/16 10:40:36 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 5, commitMemory -> 141, usedMemory ->143
18/09/16 10:40:36 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1988281306_0001_m_000021_0 decomp: 2 len: 6 to MEMORY
18/09/16 10:40:36 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1988281306_0001_m_000021_0
18/09/16 10:40:36 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 6, commitMemory -> 143, usedMemory ->145
18/09/16 10:40:36 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1988281306_0001_m_000000_0 decomp: 135 len: 139 to MEMORY
18/09/16 10:40:36 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:206)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
18/09/16 10:40:36 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:206)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
18/09/16 10:40:36 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:206)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
18/09/16 10:40:36 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:206)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
18/09/16 10:40:36 INFO reduce.InMemoryMapOutput: Read 135 bytes from map-output for attempt_local1988281306_0001_m_000000_0
18/09/16 10:40:36 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 135, inMemoryMapOutputs.size() -> 7, commitMemory -> 145, usedMemory ->280
18/09/16 10:40:36 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1988281306_0001_m_000025_0 decomp: 2 len: 6 to MEMORY
18/09/16 10:40:36 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1988281306_0001_m_000025_0
18/09/16 10:40:36 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 8, commitMemory -> 280, usedMemory ->282
18/09/16 10:40:36 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1988281306_0001_m_000013_0 decomp: 2 len: 6 to MEMORY
18/09/16 10:40:36 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1988281306_0001_m_000013_0
18/09/16 10:40:36 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 9, commitMemory -> 282, usedMemory ->284
18/09/16 10:40:36 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1988281306_0001_m_000026_0 decomp: 2 len: 6 to MEMORY
18/09/16 10:40:36 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1988281306_0001_m_000026_0
18/09/16 10:40:36 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 10, commitMemory -> 284, usedMemory ->286
18/09/16 10:40:36 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1988281306_0001_m_000011_0 decomp: 2 len: 6 to MEMORY
18/09/16 10:40:36 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1988281306_0001_m_000011_0
18/09/16 10:40:36 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 11, commitMemory -> 286, usedMemory ->288
18/09/16 10:40:36 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1988281306_0001_m_000024_0 decomp: 2 len: 6 to MEMORY
18/09/16 10:40:36 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1988281306_0001_m_000024_0
18/09/16 10:40:36 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 12, commitMemory -> 288, usedMemory ->290
18/09/16 10:40:36 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:206)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
18/09/16 10:40:36 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1988281306_0001_m_000012_0 decomp: 2 len: 6 to MEMORY
18/09/16 10:40:36 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:206)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
18/09/16 10:40:36 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1988281306_0001_m_000012_0
18/09/16 10:40:36 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:206)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
18/09/16 10:40:36 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:206)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
18/09/16 10:40:36 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:206)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
18/09/16 10:40:36 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:206)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
18/09/16 10:40:36 INFO mapreduce.Job:  map 100% reduce 0%
18/09/16 10:40:36 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 13, commitMemory -> 290, usedMemory ->292
18/09/16 10:40:36 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1988281306_0001_m_000003_0 decomp: 2 len: 6 to MEMORY
18/09/16 10:40:36 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1988281306_0001_m_000003_0
18/09/16 10:40:36 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 14, commitMemory -> 292, usedMemory ->294
18/09/16 10:40:36 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1988281306_0001_m_000016_0 decomp: 2 len: 6 to MEMORY
18/09/16 10:40:36 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1988281306_0001_m_000016_0
18/09/16 10:40:36 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 15, commitMemory -> 294, usedMemory ->296
18/09/16 10:40:36 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:206)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
18/09/16 10:40:36 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1988281306_0001_m_000004_0 decomp: 2 len: 6 to MEMORY
18/09/16 10:40:36 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1988281306_0001_m_000004_0
18/09/16 10:40:36 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 16, commitMemory -> 296, usedMemory ->298
18/09/16 10:40:36 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1988281306_0001_m_000027_0 decomp: 2 len: 6 to MEMORY
18/09/16 10:40:36 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1988281306_0001_m_000027_0
18/09/16 10:40:36 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 17, commitMemory -> 298, usedMemory ->300
18/09/16 10:40:36 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:206)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
18/09/16 10:40:36 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1988281306_0001_m_000001_0 decomp: 21 len: 25 to MEMORY
18/09/16 10:40:36 INFO reduce.InMemoryMapOutput: Read 21 bytes from map-output for attempt_local1988281306_0001_m_000001_0
18/09/16 10:40:36 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 21, inMemoryMapOutputs.size() -> 18, commitMemory -> 300, usedMemory ->321
18/09/16 10:40:36 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1988281306_0001_m_000014_0 decomp: 2 len: 6 to MEMORY
18/09/16 10:40:36 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1988281306_0001_m_000014_0
18/09/16 10:40:36 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 19, commitMemory -> 321, usedMemory ->323
18/09/16 10:40:36 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1988281306_0001_m_000015_0 decomp: 2 len: 6 to MEMORY
18/09/16 10:40:36 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1988281306_0001_m_000015_0
18/09/16 10:40:36 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 20, commitMemory -> 323, usedMemory ->325
18/09/16 10:40:36 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1988281306_0001_m_000028_0 decomp: 2 len: 6 to MEMORY
18/09/16 10:40:36 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1988281306_0001_m_000028_0
18/09/16 10:40:36 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 21, commitMemory -> 325, usedMemory ->327
18/09/16 10:40:36 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:206)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
18/09/16 10:40:36 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:206)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
18/09/16 10:40:36 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:206)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
18/09/16 10:40:36 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1988281306_0001_m_000002_0 decomp: 2 len: 6 to MEMORY
18/09/16 10:40:36 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1988281306_0001_m_000002_0
18/09/16 10:40:36 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 22, commitMemory -> 327, usedMemory ->329
18/09/16 10:40:36 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1988281306_0001_m_000019_0 decomp: 2 len: 6 to MEMORY
18/09/16 10:40:36 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1988281306_0001_m_000019_0
18/09/16 10:40:36 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 23, commitMemory -> 329, usedMemory ->331
18/09/16 10:40:36 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1988281306_0001_m_000006_0 decomp: 2 len: 6 to MEMORY
18/09/16 10:40:36 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1988281306_0001_m_000006_0
18/09/16 10:40:36 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 24, commitMemory -> 331, usedMemory ->333
18/09/16 10:40:36 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1988281306_0001_m_000007_0 decomp: 29 len: 33 to MEMORY
18/09/16 10:40:36 INFO reduce.InMemoryMapOutput: Read 29 bytes from map-output for attempt_local1988281306_0001_m_000007_0
18/09/16 10:40:36 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 29, inMemoryMapOutputs.size() -> 25, commitMemory -> 333, usedMemory ->362
18/09/16 10:40:36 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1988281306_0001_m_000020_0 decomp: 2 len: 6 to MEMORY
18/09/16 10:40:36 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1988281306_0001_m_000020_0
18/09/16 10:40:36 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 26, commitMemory -> 362, usedMemory ->364
18/09/16 10:40:36 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1988281306_0001_m_000017_0 decomp: 2 len: 6 to MEMORY
18/09/16 10:40:36 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1988281306_0001_m_000017_0
18/09/16 10:40:36 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 27, commitMemory -> 364, usedMemory ->366
18/09/16 10:40:36 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1988281306_0001_m_000005_0 decomp: 29 len: 33 to MEMORY
18/09/16 10:40:36 INFO reduce.InMemoryMapOutput: Read 29 bytes from map-output for attempt_local1988281306_0001_m_000005_0
18/09/16 10:40:36 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 29, inMemoryMapOutputs.size() -> 28, commitMemory -> 366, usedMemory ->395
18/09/16 10:40:36 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1988281306_0001_m_000018_0 decomp: 2 len: 6 to MEMORY
18/09/16 10:40:36 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1988281306_0001_m_000018_0
18/09/16 10:40:36 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 29, commitMemory -> 395, usedMemory ->397
18/09/16 10:40:36 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:206)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
18/09/16 10:40:36 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:206)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
18/09/16 10:40:36 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
18/09/16 10:40:36 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:206)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
18/09/16 10:40:36 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:206)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
18/09/16 10:40:36 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:206)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
18/09/16 10:40:36 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:206)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
18/09/16 10:40:36 INFO mapred.LocalJobRunner: 29 / 29 copied.
18/09/16 10:40:36 INFO reduce.MergeManagerImpl: finalMerge called with 29 in-memory map-outputs and 0 on-disk map-outputs
18/09/16 10:40:36 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:206)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
18/09/16 10:40:36 INFO mapred.Merger: Merging 29 sorted segments
18/09/16 10:40:36 INFO mapred.Merger: Down to the last merge-pass, with 6 segments left of total size: 241 bytes
18/09/16 10:40:36 INFO reduce.MergeManagerImpl: Merged 29 segments, 397 bytes to disk to satisfy reduce memory limit
18/09/16 10:40:36 INFO reduce.MergeManagerImpl: Merging 1 files, 345 bytes from disk
18/09/16 10:40:36 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
18/09/16 10:40:36 INFO mapred.Merger: Merging 1 sorted segments
18/09/16 10:40:36 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 310 bytes
18/09/16 10:40:36 INFO mapred.LocalJobRunner: 29 / 29 copied.
18/09/16 10:40:36 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
18/09/16 10:40:36 INFO mapred.Task: Task:attempt_local1988281306_0001_r_000000_0 is done. And is in the process of committing
18/09/16 10:40:36 INFO mapred.LocalJobRunner: 29 / 29 copied.
18/09/16 10:40:36 INFO mapred.Task: Task attempt_local1988281306_0001_r_000000_0 is allowed to commit now
18/09/16 10:40:36 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1988281306_0001_r_000000_0' to hdfs://localhost:9000/user/gwang39/grep-temp-1982783859/_temporary/0/task_local1988281306_0001_r_000000
18/09/16 10:40:36 INFO mapred.LocalJobRunner: reduce > reduce
18/09/16 10:40:36 INFO mapred.Task: Task 'attempt_local1988281306_0001_r_000000_0' done.
18/09/16 10:40:36 INFO mapred.LocalJobRunner: Finishing task: attempt_local1988281306_0001_r_000000_0
18/09/16 10:40:36 INFO mapred.LocalJobRunner: reduce task executor complete.
18/09/16 10:40:37 INFO mapreduce.Job:  map 100% reduce 100%
18/09/16 10:40:37 INFO mapreduce.Job: Job job_local1988281306_0001 completed successfully
18/09/16 10:40:37 INFO mapreduce.Job: Counters: 35
	File System Counters
		FILE: Number of bytes read=10127292
		FILE: Number of bytes written=17704592
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=1763334
		HDFS: Number of bytes written=437
		HDFS: Number of read operations=1021
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=32
	Map-Reduce Framework
		Map input records=2068
		Map output records=24
		Map output bytes=590
		Map output materialized bytes=513
		Input split bytes=3563
		Combine input records=24
		Combine output records=13
		Reduce input groups=11
		Reduce shuffle bytes=513
		Reduce input records=13
		Reduce output records=11
		Spilled Records=26
		Shuffled Maps =29
		Failed Shuffles=0
		Merged Map outputs=29
		GC time elapsed (ms)=227
		Total committed heap usage (bytes)=15271985152
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=76870
	File Output Format Counters 
		Bytes Written=437
18/09/16 10:40:37 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
18/09/16 10:40:37 INFO input.FileInputFormat: Total input paths to process : 1
18/09/16 10:40:37 INFO mapreduce.JobSubmitter: number of splits:1
18/09/16 10:40:37 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1171382001_0002
18/09/16 10:40:37 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
18/09/16 10:40:37 INFO mapreduce.Job: Running job: job_local1171382001_0002
18/09/16 10:40:37 INFO mapred.LocalJobRunner: OutputCommitter set in config null
18/09/16 10:40:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/09/16 10:40:37 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
18/09/16 10:40:37 INFO mapred.LocalJobRunner: Waiting for map tasks
18/09/16 10:40:37 INFO mapred.LocalJobRunner: Starting task: attempt_local1171382001_0002_m_000000_0
18/09/16 10:40:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/09/16 10:40:37 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
18/09/16 10:40:37 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/gwang39/grep-temp-1982783859/part-r-00000:0+437
18/09/16 10:40:37 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
18/09/16 10:40:37 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
18/09/16 10:40:37 INFO mapred.MapTask: soft limit at 83886080
18/09/16 10:40:37 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
18/09/16 10:40:37 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
18/09/16 10:40:37 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
18/09/16 10:40:37 INFO mapred.LocalJobRunner: 
18/09/16 10:40:37 INFO mapred.MapTask: Starting flush of map output
18/09/16 10:40:37 INFO mapred.MapTask: Spilling map output
18/09/16 10:40:37 INFO mapred.MapTask: bufstart = 0; bufend = 263; bufvoid = 104857600
18/09/16 10:40:37 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214356(104857424); length = 41/6553600
18/09/16 10:40:37 INFO mapred.MapTask: Finished spill 0
18/09/16 10:40:37 INFO mapred.Task: Task:attempt_local1171382001_0002_m_000000_0 is done. And is in the process of committing
18/09/16 10:40:37 INFO mapred.LocalJobRunner: map
18/09/16 10:40:37 INFO mapred.Task: Task 'attempt_local1171382001_0002_m_000000_0' done.
18/09/16 10:40:37 INFO mapred.LocalJobRunner: Finishing task: attempt_local1171382001_0002_m_000000_0
18/09/16 10:40:37 INFO mapred.LocalJobRunner: map task executor complete.
18/09/16 10:40:37 INFO mapred.LocalJobRunner: Waiting for reduce tasks
18/09/16 10:40:37 INFO mapred.LocalJobRunner: Starting task: attempt_local1171382001_0002_r_000000_0
18/09/16 10:40:37 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/09/16 10:40:37 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
18/09/16 10:40:37 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7e75a580
18/09/16 10:40:37 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=373240608, maxSingleShuffleLimit=93310152, mergeThreshold=246338816, ioSortFactor=10, memToMemMergeOutputsThreshold=10
18/09/16 10:40:37 INFO reduce.EventFetcher: attempt_local1171382001_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
18/09/16 10:40:37 INFO reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1171382001_0002_m_000000_0 decomp: 287 len: 291 to MEMORY
18/09/16 10:40:37 INFO reduce.InMemoryMapOutput: Read 287 bytes from map-output for attempt_local1171382001_0002_m_000000_0
18/09/16 10:40:37 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 287, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->287
18/09/16 10:40:37 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
18/09/16 10:40:37 INFO mapred.LocalJobRunner: 1 / 1 copied.
18/09/16 10:40:37 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
18/09/16 10:40:37 INFO mapred.Merger: Merging 1 sorted segments
18/09/16 10:40:37 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 277 bytes
18/09/16 10:40:37 INFO reduce.MergeManagerImpl: Merged 1 segments, 287 bytes to disk to satisfy reduce memory limit
18/09/16 10:40:37 INFO reduce.MergeManagerImpl: Merging 1 files, 291 bytes from disk
18/09/16 10:40:37 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
18/09/16 10:40:37 INFO mapred.Merger: Merging 1 sorted segments
18/09/16 10:40:37 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 277 bytes
18/09/16 10:40:37 INFO mapred.LocalJobRunner: 1 / 1 copied.
18/09/16 10:40:37 INFO mapred.Task: Task:attempt_local1171382001_0002_r_000000_0 is done. And is in the process of committing
18/09/16 10:40:37 INFO mapred.LocalJobRunner: 1 / 1 copied.
18/09/16 10:40:37 INFO mapred.Task: Task attempt_local1171382001_0002_r_000000_0 is allowed to commit now
18/09/16 10:40:37 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1171382001_0002_r_000000_0' to hdfs://localhost:9000/user/gwang39/output/_temporary/0/task_local1171382001_0002_r_000000
18/09/16 10:40:37 INFO mapred.LocalJobRunner: reduce > reduce
18/09/16 10:40:37 INFO mapred.Task: Task 'attempt_local1171382001_0002_r_000000_0' done.
18/09/16 10:40:37 INFO mapred.LocalJobRunner: Finishing task: attempt_local1171382001_0002_r_000000_0
18/09/16 10:40:37 INFO mapred.LocalJobRunner: reduce task executor complete.
18/09/16 10:40:38 INFO mapreduce.Job: Job job_local1171382001_0002 running in uber mode : false
18/09/16 10:40:38 INFO mapreduce.Job:  map 100% reduce 100%
18/09/16 10:40:38 INFO mapreduce.Job: Job job_local1171382001_0002 completed successfully
18/09/16 10:40:38 INFO mapreduce.Job: Counters: 35
	File System Counters
		FILE: Number of bytes read=1311958
		FILE: Number of bytes written=2350325
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=154614
		HDFS: Number of bytes written=1071
		HDFS: Number of read operations=151
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=16
	Map-Reduce Framework
		Map input records=11
		Map output records=11
		Map output bytes=263
		Map output materialized bytes=291
		Input split bytes=133
		Combine input records=0
		Combine output records=0
		Reduce input groups=5
		Reduce shuffle bytes=291
		Reduce input records=11
		Reduce output records=11
		Spilled Records=22
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=1066401792
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=437
	File Output Format Counters 
		Bytes Written=197
]777;notify;Command completed;bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar grep input output 'dfs[a-z.]+']0;gwang39@hdserver:~/hadoop-2.7.3]7;file://hdserver/home/gwang39/hadoop-2.7.3[gwang39@hdserver hadoop-2.7.3]$ exit
exit

Script done on Sun 16 Sep 2018 10:42:34 AM EDT
